{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 3\n",
    "\n",
    "Neste desafio, iremos praticar nossos conhecimentos sobre distribuições de probabilidade. Para isso,\n",
    "dividiremos este desafio em duas partes:\n",
    "    \n",
    "1. A primeira parte contará com 3 questões sobre um *data set* artificial com dados de uma amostra normal e\n",
    "    uma binomial.\n",
    "2. A segunda parte será sobre a análise da distribuição de uma variável do _data set_ [Pulsar Star](https://archive.ics.uci.edu/ml/datasets/HTRU2), contendo 2 questões.\n",
    "\n",
    "> Obs.: Por favor, não modifique o nome das funções de resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Setup_ geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sct\n",
    "import seaborn as sns\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "#from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "#figsize(12, 8)\n",
    "\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setup_ da parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "    \n",
    "dataframe = pd.DataFrame({\"normal\": sct.norm.rvs(20, 4, size=10000),\n",
    "                     \"binomial\": sct.binom.rvs(100, 0.2, size=10000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua análise da parte 1 começa aqui.\n",
    "df = dataframe.describe()\n",
    "\n",
    "#dataframe['normal'].plot(kind='hist',alpha=0.6)\n",
    "#dataframe['binomial'].plot(kind='hist',alpha=0.6)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Qual a diferença entre os quartis (Q1, Q2 e Q3) das variáveis `normal` e `binomial` de `dataframe`? Responda como uma tupla de três elementos arredondados para três casas decimais.\n",
    "\n",
    "Em outra palavras, sejam `q1_norm`, `q2_norm` e `q3_norm` os quantis da variável `normal` e `q1_binom`, `q2_binom` e `q3_binom` os quantis da variável `binom`, qual a diferença `(q1_norm - q1 binom, q2_norm - q2_binom, q3_norm - q3_binom)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    # Retorne aqui o resultado da questão 1.\n",
    "    q1_norm = df['normal']['25%']\n",
    "    q2_norm = df['normal']['50%']\n",
    "    q3_norm = df['normal']['75%']\n",
    "\n",
    "    q1_binom = df['binomial']['25%']\n",
    "    q2_binom = df['binomial']['50%']\n",
    "    q3_binom = df['binomial']['75%']\n",
    "    \n",
    "    x1 = round(q1_norm-q1_binom,3)\n",
    "    x2 = round(q2_norm-q2_binom,3)\n",
    "    x3 = round(q3_norm-q3_binom,3)\n",
    "    \n",
    "    return (x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Você esperava valores dessa magnitude?\n",
    "\n",
    "* Você é capaz de explicar como distribuições aparentemente tão diferentes (discreta e contínua, por exemplo) conseguem dar esses valores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Considere o intervalo $[\\bar{x} - s, \\bar{x} + s]$, onde $\\bar{x}$ é a média amostral e $s$ é o desvio padrão. Qual a probabilidade nesse intervalo, calculada pela função de distribuição acumulada empírica (CDF empírica) da variável `normal`? Responda como uma único escalar arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2():\n",
    "    # Retorne aqui o resultado da questão 2.\n",
    "    std_value = dataframe.normal.std()\n",
    "    mean_value = dataframe.normal.mean()\n",
    "       \n",
    "    ecdf = ECDF(dataframe['normal'])\n",
    "    x_minus_std = mean_value - std_value\n",
    "    x_plus_std = mean_value + std_value\n",
    "    x = round(ecdf(x_plus_std) - ecdf(x_minus_std),3)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Esse valor se aproxima do esperado teórico?\n",
    "* Experimente também para os intervalos $[\\bar{x} - 2s, \\bar{x} + 2s]$ e $[\\bar{x} - 3s, \\bar{x} + 3s]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "\n",
    "Qual é a diferença entre as médias e as variâncias das variáveis `binomial` e `normal`? Responda como uma tupla de dois elementos arredondados para três casas decimais.\n",
    "\n",
    "Em outras palavras, sejam `m_binom` e `v_binom` a média e a variância da variável `binomial`, e `m_norm` e `v_norm` a média e a variância da variável `normal`. Quais as diferenças `(m_binom - m_norm, v_binom - v_norm)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3():\n",
    "    # Retorne aqui o resultado da questão 3.\n",
    "    m_norm = df['normal']['mean']\n",
    "    v_norm = df['normal']['std'] ** 2\n",
    "    \n",
    "    m_binom = df['binomial']['mean']\n",
    "    v_binom = df['binomial']['std'] ** 2\n",
    "    \n",
    "    x1 = round(m_binom - m_norm,3)\n",
    "    x2 = round(v_binom - v_norm,3)\n",
    "    return (x1,x2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Você esperava valore dessa magnitude?\n",
    "* Qual o efeito de aumentar ou diminuir $n$ (atualmente 100) na distribuição da variável `binomial`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setup_ da parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = pd.read_csv(\"pulsar_stars.csv\")\n",
    "\n",
    "stars.rename({old_name: new_name\n",
    "              for (old_name, new_name)\n",
    "              in zip(stars.columns,\n",
    "                     [\"mean_profile\", \"sd_profile\", \"kurt_profile\", \"skew_profile\", \"mean_curve\", \"sd_curve\", \"kurt_curve\", \"skew_curve\", \"target\"])\n",
    "             },\n",
    "             axis=1, inplace=True)\n",
    "\n",
    "stars.loc[:, \"target\"] = stars.target.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicie sua análise da parte 2 a partir daqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_profile</th>\n",
       "      <th>sd_profile</th>\n",
       "      <th>kurt_profile</th>\n",
       "      <th>skew_profile</th>\n",
       "      <th>mean_curve</th>\n",
       "      <th>sd_curve</th>\n",
       "      <th>kurt_curve</th>\n",
       "      <th>skew_curve</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.570312</td>\n",
       "      <td>46.698114</td>\n",
       "      <td>0.531905</td>\n",
       "      <td>0.416721</td>\n",
       "      <td>1.636288</td>\n",
       "      <td>14.545074</td>\n",
       "      <td>10.621748</td>\n",
       "      <td>131.394004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119.484375</td>\n",
       "      <td>48.765059</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>-0.112168</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>9.279612</td>\n",
       "      <td>19.206230</td>\n",
       "      <td>479.756567</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130.382812</td>\n",
       "      <td>39.844056</td>\n",
       "      <td>-0.158323</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>1.220736</td>\n",
       "      <td>14.378941</td>\n",
       "      <td>13.539456</td>\n",
       "      <td>198.236457</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_profile  sd_profile  kurt_profile  skew_profile  mean_curve  \\\n",
       "0    102.507812   58.882430      0.465318     -0.515088    1.677258   \n",
       "1    103.015625   39.341649      0.323328      1.051164    3.121237   \n",
       "2    136.750000   57.178449     -0.068415     -0.636238    3.642977   \n",
       "3     88.726562   40.672225      0.600866      1.123492    1.178930   \n",
       "4     93.570312   46.698114      0.531905      0.416721    1.636288   \n",
       "5    119.484375   48.765059      0.031460     -0.112168    0.999164   \n",
       "6    130.382812   39.844056     -0.158323      0.389540    1.220736   \n",
       "\n",
       "    sd_curve  kurt_curve  skew_curve  target  \n",
       "0  14.860146   10.576487  127.393580   False  \n",
       "1  21.744669    7.735822   63.171909   False  \n",
       "2  20.959280    6.896499   53.593661   False  \n",
       "3  11.468720   14.269573  252.567306   False  \n",
       "4  14.545074   10.621748  131.394004   False  \n",
       "5   9.279612   19.206230  479.756567   False  \n",
       "6  14.378941   13.539456  198.236457   False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sua análise da parte 2 começa aqui.\n",
    "stars.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n",
    "\n",
    "Considerando a variável `mean_profile` de `stars`:\n",
    "\n",
    "1. Filtre apenas os valores de `mean_profile` onde `target == 0` (ou seja, onde a estrela não é um pulsar).\n",
    "2. Padronize a variável `mean_profile` filtrada anteriormente para ter média 0 e variância 1.\n",
    "\n",
    "Chamaremos a variável resultante de `false_pulsar_mean_profile_standardized`.\n",
    "\n",
    "Encontre os quantis teóricos para uma distribuição normal de média 0 e variância 1 para 0.80, 0.90 e 0.95 através da função `norm.ppf()` disponível em `scipy.stats`.\n",
    "\n",
    "Quais as probabilidade associadas a esses quantis utilizando a CDF empírica da variável `false_pulsar_mean_profile_standardized`? Responda como uma tupla de três elementos arredondados para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4():\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    df = stars[stars['target'] == False]['mean_profile']\n",
    "    # padronização da coluna\n",
    "    false_pulsar_mean_profile_standardized  = (df - df.mean())/df.std()\n",
    "    # acha o valor de 'x' correspondente a probabilidade acumulada\n",
    "    valor_probcum_menor_80porcento = sct.norm.ppf(0.8, loc=0, scale=1)\n",
    "    valor_probcum_menor_90porcento = sct.norm.ppf(0.9, loc=0, scale=1)\n",
    "    valor_probcum_menor_95porcento = sct.norm.ppf(0.95, loc=0, scale=1)\n",
    "    \n",
    "    #calcula a probabilidade acumulada para utilizando o ECDF\n",
    "    ecdf =ECDF(false_pulsar_mean_profile_standardized)\n",
    "    prob_ecdf_80porcento = round(ecdf(valor_probcum_menor_80porcento),3)\n",
    "    prob_ecdf_90porcento = round(ecdf(valor_probcum_menor_90porcento),3)\n",
    "    prob_ecdf_95porcento = round(ecdf(valor_probcum_menor_95porcento),3)\n",
    "    \n",
    "    return (prob_ecdf_80porcento, prob_ecdf_90porcento, prob_ecdf_95porcento)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Os valores encontrados fazem sentido?\n",
    "* O que isso pode dizer sobre a distribuição da variável `false_pulsar_mean_profile_standardized`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5\n",
    "\n",
    "Qual a diferença entre os quantis Q1, Q2 e Q3 de `false_pulsar_mean_profile_standardized` e os mesmos quantis teóricos de uma distribuição normal de média 0 e variância 1? Responda como uma tupla de três elementos arredondados para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def q5():\n",
    "    # Retorne aqui o resultado da questão 5.\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    df = stars[stars['target'] == False]['mean_profile']\n",
    "    # padronização da coluna\n",
    "    false_pulsar_mean_profile_standardized  = (df - df.mean())/df.std()\n",
    "    \n",
    "    # quantis da distribuição normal com media 0 e variancia 1\n",
    "    q1_normal = sct.norm.ppf(0.25, loc=0, scale=1)\n",
    "    q2_normal = sct.norm.ppf(0.5, loc=0, scale=1)\n",
    "    q3_normal = sct.norm.ppf(0.75, loc=0, scale=1)\n",
    "    #quantis da distribuição padronizada\n",
    "    q1 = np.quantile(false_pulsar_mean_profile_standardized,q=.25)\n",
    "    q2 = np.quantile(false_pulsar_mean_profile_standardized,q=.5)\n",
    "    q3 = np.quantile(false_pulsar_mean_profile_standardized,q=.75)\n",
    "    \n",
    "    d1 = round(q1 - q1_normal,3)\n",
    "    d2 = round(q2 - q2_normal,3)\n",
    "    d3 = round(q3 - q3_normal,3)\n",
    "    \n",
    "    return (d1,d2,d3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para refletir:\n",
    "\n",
    "* Os valores encontrados fazem sentido?\n",
    "* O que isso pode dizer sobre a distribuição da variável `false_pulsar_mean_profile_standardized`?\n",
    "* Curiosidade: alguns testes de hipóteses sobre normalidade dos dados utilizam essa mesma abordagem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
